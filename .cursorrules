# Nansen API Configuration for Cursor

## Core Settings

BASE_URL: https://api.nansen.ai/api/beta
AUTH_HEADER: apiKey
RATE_LIMIT: 20req/s, 500req/min

## Authentication & Security

API_KEY_SOURCE: The API key is ALWAYS stored in the .env file as 'apiKey'

- NEVER ask users for API keys
- ALWAYS fetch the API key from the .env file
- Use `apiKey` variable from .env for all API calls
- Read the key value from .env for runtime execution

## Rate Limiting & Performance

- Implement exponential backoff for rate limit errors
- Cache frequently requested data when appropriate
- Monitor and log API usage patterns

# Token Analysis Automation

## Address Discovery Rules

TOKEN_ADDRESS_SEARCH: When a token symbol is mentioned without an address, automatically search the internet for the token's contract address on the relevant blockchain.

### Search Triggers:

- User mentions token symbol without providing contract address
- User asks to "monitor [TOKEN]" or "analyze [TOKEN]" without address
- When implementing new token analysis features

### Search Patterns:

Use search queries like: "TOKEN_SYMBOL contract address blockchain_name" or "TOKEN_SYMBOL token address solscan etherscan"

### Search Sources Priority:

1. Solscan.io for Solana tokens
2. Etherscan.io for Ethereum tokens
3. CoinGecko for multi-chain token information
4. DexScreener for DEX-traded tokens
5. Official project documentation/websites

## Default Parameters

DEFAULT_CHAINS: ethereum, solana
DEFAULT_TIMEFRAMES: 1d, 7d, 30d
DEFAULT_PAGINATION: 50 records per page
DEFAULT_SM_FILTERS: "180D Smart Trader", "Fund", "Smart Trader"

# API Interaction Standards

## Endpoint Compliance

ENDPOINT_RESTRICTION: ONLY use endpoints documented in the official Nansen API documentation

- Do NOT use undocumented endpoints
- Do NOT guess API paths or parameters
- Reference the official Nansen API documentation for all calls
- Validate endpoint availability before execution

## Parameter Validation Process

Before executing ANY API call:

1. Review API documentation to identify ALL required parameters
2. Cross-check user's request against documented required parameters
3. If ANY required parameter is missing, ask user to confirm/provide it
4. List all required parameters needing confirmation with descriptions
5. Do NOT make assumptions about missing required parameters
6. Do NOT provide default values for required parameters without user confirmation
7. Only execute after ALL required parameters are explicitly confirmed
8. Validate parameter types and formats against API documentation

## Error Handling

- API_ERROR_400: Validate all parameters and suggest corrections
- API_ERROR_429: Implement retry logic with backoff
- API_ERROR_500: Log error details and suggest alternative approaches
- INVALID_RESPONSE: Debug API call and suggest fixes
- Provide clear error messages with suggested solutions

## Response Formatting

- Present data in structured, readable formats
- Use tables for comparative data
- Highlight key metrics and insights
- Include data source timestamps
- Provide context for numerical values

# User Experience

## Command Execution Preferences

When users request API calls, intelligently choose between:

- **Simple cURL command**: For immediate, one-time execution
- **Python/JavaScript script**: For complex logic, reusable automation, or multi-step processes

### Decision Criteria:

- Single API call with simple parameters → cURL
- Multiple API calls or data processing → Script
- User explicitly requests specific format → Honor request
- Complex filtering/analysis required → Script

## Output Standards

- Always include execution instructions
- Include error handling guidance
- Show expected response formats
- Offer both technical and business interpretations

## Debugging Support

- Log API request/response details when errors occur
- Provide troubleshooting steps for common issues
- Include relevant documentation links
- Suggest parameter alternatives when validation fails

# Automation Intelligence

## Smart Actions

- NEW_TOKEN_ANALYSIS: Automatically look up token info and recent news
- MISSING_DATA: Suggest alternative data sources or timeframes
- PERFORMANCE_OPTIMIZATION: Recommend caching strategies for repeated queries
- TREND_ANALYSIS: Automatically identify and highlight significant patterns

## Quality Assurance

- Verify data consistency across multiple timeframes
- Cross-reference critical metrics with alternative sources
- Flag unusual patterns or potential data anomalies
- Provide confidence indicators for automated insights
